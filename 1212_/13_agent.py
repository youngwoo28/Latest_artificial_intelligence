import os
from dotenv import load_dotenv

# LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_core.tools import Tool
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage
from langchain.agents import create_agent

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆ ì„í¬íŠ¸
# 1. QnA Class (12_qna_class.py)
# ì£¼ì˜: íŒŒì¼ëª…ì´ ìˆ«ìë¡œ ì‹œì‘í•˜ë¯€ë¡œ importlibì„ ì‚¬ìš©í•˜ê±°ë‚˜, ê°™ì€ ë””ë ‰í† ë¦¬ë¼ë©´ ê·¸ëƒ¥ import ê°€ëŠ¥í•˜ì§€ë§Œ
# íŒŒì´ì¬ ë³€ìˆ˜ëª… ê·œì¹™ìƒ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“ˆì€ import ë¬¸ìœ¼ë¡œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° ê¹Œë‹¤ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì¼ë°˜ì ì¸ importê°€ ë™ì‘í•œë‹¤ê³  ê°€ì •í•˜ê³  ì‹œë„í•´ë´…ë‹ˆë‹¤.
# ë§Œì•½ import ì—ëŸ¬ê°€ ë‚˜ë©´ importlibì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
# ë³´í†µ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ì€ import 12_qna_class ê°€ ì•ˆë˜ë¯€ë¡œ, 
# from ... import ... êµ¬ë¬¸ë„ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì¼ë‹¨ importlibì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê² ìŠµë‹ˆë‹¤.
import importlib

# 12_qna_class.py ë™ì  ì„í¬íŠ¸
qna_module = importlib.import_module("12_qna_class")
QnAAgent = qna_module.QnAAgent

# 13_travily_class.py ë™ì  ì„í¬íŠ¸
# 13_travily_class.py ë™ì  ì„í¬íŠ¸
travily_module = importlib.import_module("13_travily_class")
TavilySearchAgent = travily_module.TavilySearchAgent

#custom_tool_module = importlib.import_module("13_custom_tool")
custom_tool_module = importlib.import_module("13_custom_tool")
add_numbers = custom_tool_module.add_numbers
multiply_numbers = custom_tool_module.multiply_numbers

#from langchain_core.tools import tool
#@tool
#def add_numbers(a: int, b: int) -> int:
#    """Add two numbers"""
#    return a + b
#
#@tool
#def multiply_numbers(a: int, b: int) -> int:
#    """Multiply two numbers"""
#    return a * b

# Helper function to print answer and tool usage
def print_result_with_tool_usage(result):
    from langchain_core.messages import AIMessage
    
    # 1. Collect used tools
    used_tools = []
    # ê²°ê³¼ê°€ dictì´ê³  messages í‚¤ê°€ ìˆëŠ” ê²½ìš° (LangGraph agent)
    if isinstance(result, dict) and "messages" in result:
        for msg in result["messages"]:
            if isinstance(msg, AIMessage) and msg.tool_calls:
                for tool_call in msg.tool_calls:
                    used_tools.append(tool_call['name'])
        final_content = result["messages"][-1].content
    else:
        # Fallback
        final_content = str(result)
    
    if used_tools:
        print(f"ğŸ› ï¸  ì‚¬ìš©ëœ ë„êµ¬: {', '.join(used_tools)}")
    else:
        print("ğŸ› ï¸  ì‚¬ìš©ëœ ë„êµ¬: ì—†ìŒ")

    # 2. Print final answer
    print("ë‹µë³€:", final_content)

def main():
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # LangSmith ëª¨ë‹ˆí„°ë§ ì„¤ì •
    # .env íŒŒì¼ì— LANGCHAIN_API_KEYê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # ë§Œì•½ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ê°•ì œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    if os.getenv("LANGCHAIN_TRACING_V2") is None:
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
    
    # í”„ë¡œì íŠ¸ ì´ë¦„ì€ ì›í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš” on LangSmith >> Projects
    os.environ["LANGCHAIN_PROJECT"] = "Ollama-Agent-Monitoring"

    # API Key í™•ì¸
    if not os.getenv("LANGCHAIN_API_KEY"):
        print("âš ï¸  WARNING: LANGCHAIN_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LangSmith ëª¨ë‹ˆí„°ë§ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"âœ… LangSmith Tracing Enabled (Project: {os.getenv('LANGCHAIN_PROJECT')})")


    # 1. LLM ì´ˆê¸°í™” (Ollama ì‚¬ìš©)
    llm = ChatOllama(
        base_url="http://localhost:11434",
        model="kimjk/llama3.2-korean"
    )
    print("âœ… LLM(kimjk/llama3.2-korean) ì´ˆê¸°í™” ì™„ë£Œ")

    # 2. ë„êµ¬(Tools) ì¤€ë¹„

    # (1) QnA ì—ì´ì „íŠ¸ ë„êµ¬
    # QnAAgent ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    qna_agent_instance = QnAAgent()
    
    # QnA ê¸°ëŠ¥ì„ Toolë¡œ ë˜í•‘
    qna_tool = Tool(
        name="SPRi_QA",
        func=qna_agent_instance.answer,
        description="SPRi AI Brief ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì…ë ¥ê°’ì€ ì§ˆë¬¸ ë¬¸ìì—´ì…ë‹ˆë‹¤.",
        return_direct=True
    )

    # (2) Tavily ê²€ìƒ‰ ì—ì´ì „íŠ¸ ë„êµ¬
    tavily_agent_instance = TavilySearchAgent()
    # TavilySearchAgentì—ì„œ ì œê³µí•˜ëŠ” ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
    search_tool = tavily_agent_instance.get_general_search_tool()
    # ë„êµ¬ ì´ë¦„ê³¼ ì„¤ëª…ì´ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆì§€ë§Œ, í•„ìš”í•˜ë‹¤ë©´ ìˆ˜ì • ê°€ëŠ¥
    search_tool.name = "Web_Search"
    search_tool.description = "ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë°˜ë“œì‹œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."

    # (3) ì»¤ìŠ¤í…€ ê³„ì‚° ë„êµ¬
    # add_numbers, multiply_numbersëŠ” ì´ë¯¸ @tool ë°ì½”ë ˆì´í„°ë¡œ ì •ì˜ë¨

    # ëª¨ë“  ë„êµ¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
    tools = [
        qna_tool,
        search_tool,
        add_numbers,
        multiply_numbers
    ]
    
    print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[t.name for t in tools]}")

    # 3. ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (create_agent ì‚¬ìš©)
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜: ë£¨í”„ ë°©ì§€ ë° ë„êµ¬ ì‚¬ìš© ê°€ì´ë“œ
    system_prompt = (
        "ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì„¸ìš”. "
        "ë„êµ¬ê°€ ë°˜í™˜í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. "
        "ë§Œì•½ ë„êµ¬ì—ì„œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì–»ì§€ ëª»í–ˆë‹¤ë©´, ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•˜ê±°ë‚˜ ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”. "
        "ì ˆëŒ€ë¡œ ë™ì¼í•œ ì…ë ¥ìœ¼ë¡œ ê°™ì€ ë„êµ¬ë¥¼ ë°˜ë³µí•´ì„œ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”. "
        "ìµœì¢… ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    )
    
    # ì—ì´ì „íŠ¸ ìƒì„± (LangGraph ê¸°ë°˜)
    agent = create_agent(llm, tools, system_prompt=system_prompt)

    print("âœ… ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ (create_agent + System Prompt)")

    # 4. ì—ì´ì „íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    print("\n========== ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ==========")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 1: PDF ë¬¸ì„œ ê´€ë ¨ ì§ˆë¬¸
    query1 = "SPRi AI Brief ë¬¸ì„œ ë‚´ìš© ì¤‘ êµ¬ê¸€ì˜ ìµœì‹  ë™ì˜ìƒ ìƒì„± AI ëª¨ë¸ ì´ë¦„ì€ ë­ì•¼?"
    print(f"\n[ì§ˆë¬¸ 1] {query1}")
    result = agent.invoke({"messages": [HumanMessage(content=query1)]})
    print_result_with_tool_usage(result)

    # ì‹œë‚˜ë¦¬ì˜¤ 2: ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
    query2 = "í˜„ì¬ í•œêµ­ì˜ ëŒ€í†µë ¹ì´ ëˆ„êµ¬ì¸ì§€ ì›¹ ê²€ìƒ‰ì„ í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”"
    print(f"\n[ì§ˆë¬¸ 2] {query2}")
    result = agent.invoke({"messages": [HumanMessage(content=query2)]})
    print_result_with_tool_usage(result)

    # ì‹œë‚˜ë¦¬ì˜¤ 3: ê³„ì‚°ì´ í•„ìš”í•œ ì§ˆë¬¸
    query3 = "123 ë”í•˜ê¸° 456ì€ ëª‡ì´ì•¼? ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ì— 2ë¥¼ ê³±í•´ì¤˜."
    print(f"\n[ì§ˆë¬¸ 3] {query3}")
    result = agent.invoke({"messages": [HumanMessage(content=query3)]})
    print_result_with_tool_usage(result)

if __name__ == "__main__":
    main()