import os
from dotenv import load_dotenv
from pathlib import Path

# ğŸ”¹ LangChain / OpenAI ëª¨ë“ˆ
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# ===============================
# 1. í™˜ê²½ì„¤ì • (.env ë¡œë“œ)
# ===============================
dotenv_path = Path(__file__).parent / ".env"
load_dotenv(dotenv_path)

langsmith_key = os.getenv("LANGSMITH_API_KEY")
openai_key = os.getenv("OPENAI_API_KEY")

print("ğŸ“¦ LANGSMITH_API_KEY =", langsmith_key)
print("ğŸ“¦ OPENAI_API_KEY =", openai_key[:8] + "..." if openai_key else "âŒ ì—†ìŒ")

if not openai_key:
    print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit(1)

# LangSmith ì¶”ì  í™œì„±í™”
os.environ["LANGCHAIN_TRACING_V2"] = "true"


# ===============================
# 2. ê¸°ë³¸ ëª¨ë¸ ì´ˆê¸°í™”
# ===============================
llm = ChatOpenAI(model="gpt-4o-mini", api_key=openai_key)


# ===============================
# 3. ì˜ˆì œ 3.1 â€” ê¸°ë³¸ ì˜ˆì œ
# ===============================
print("\nğŸ§© [3.1 ê¸°ë³¸ ì˜ˆì œ]")
response = llm.invoke("ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ”?")
print("ğŸ’¬ ì‘ë‹µ:", response.content)












# ===============================
# 4. ì˜ˆì œ 3.2 â€” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©
# ===============================
print("\nğŸ§© [3.2 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©]")

prompt = ChatPromptTemplate.from_template(
    "You are an expert in astronomy. Answer the question. <Question>: {input}"
)

chain = prompt | llm
response = chain.invoke({"input": "ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ”?"})
print("ğŸ’¬ ì‘ë‹µ:", response.content)












# ===============================
# 5. ì˜ˆì œ 3.3 â€” ì¶œë ¥ ê²°ê³¼ íŒŒì‹± (ë¬¸ìì—´ ë³€í™˜)
# ===============================
print("\nğŸ§© [3.3 ì¶œë ¥ ê²°ê³¼ íŒŒì‹±]")

prompt = ChatPromptTemplate.from_template(
    "You are an expert in astronomy. Answer the question. <Question>: {input}"
)
output_parser = StrOutputParser()
chain = prompt | llm | output_parser

response = chain.invoke({"input": "ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ”?"})
print("ğŸ’¬ ì‘ë‹µ:", response)











# ===============================
# 6. ì˜ˆì œ 3.4 â€” ë©€í‹° ì²´ì¸ (í•œêµ­ì–´ â†’ ì˜ì–´ â†’ ì„¤ëª…)
# ===============================
print("\nğŸ§© [3.4 ë©€í‹° ì²´ì¸ ì˜ˆì œ]")

# ì²« ë²ˆì§¸ ì²´ì¸: í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­
prompt1 = ChatPromptTemplate.from_template("translate {korean_word} to English.")
# ë‘ ë²ˆì§¸ ì²´ì¸: ì˜ì–´ ë‹¨ì–´ ì˜ë¯¸ ì„¤ëª…
prompt2 = ChatPromptTemplate.from_template(
    "explain {english_word} using Oxford dictionary to me in Korean."
)

# ì²´ì¸ êµ¬ì„±
chain1 = prompt1 | llm | StrOutputParser()
chain2 = ({"english_word": chain1} | prompt2 | llm | StrOutputParser())

response = chain2.invoke({"korean_word": "ë¯¸ë˜"})
print("ğŸ’¬ ì‘ë‹µ:", response)











# ===============================
# 7. ì¢…ë£Œ ë©”ì‹œì§€
# ===============================
print("\nâœ… ëª¨ë“  LangChain + OpenAI ì˜ˆì œê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
